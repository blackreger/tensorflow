#coding = utf-8
'''
关于优化算法
优化算法的功能是通过改善训练方式，来最小化或最大化损失函数

梯度下降法
主要用于在神经网络模型中进行权重更新，即在一个方向上更新和调整模型的参数，来最小化损失函数
标准梯度下降
更新参数公式：θ=θ−η×∇(θ).J(θ) ，η是学习率，∇(θ).J(θ)是损失函数J(θ)的梯度。
权重更新的快慢是由学习率η决定的。但是在训练大型数据集时存在冗余的权重更新
随机梯度下降
批量梯度下降


关于优化器
tf.train.GradientDescentOptimizer(梯度下降法)
标准梯度下降法-计算所有样本汇总误差，根据总误差更新权值
随机梯度下降法(SGD)-随机抽取一个样本来计算误差，更新权值
批量梯度下降法-从所有样本中选取一个批次，根据这个批次的误差来更新权值

Momentum和NAG
tf.train.MomentumOptimizer()

Adagrad

'''
