#coding=utf-8
"""
代价是预测值和实际值之间的差距，对于多个样本来说就是差距的和
为什么计算差距还会有一个代价函数呢，这年头干啥不需要一个函数呢
简单神经网络的计算思路即使用各个网络层最后计算出的结果(加上偏置)，使用激活函数得到输出值，使用代价函数计算代价

二次代价函数－－差值的平方和除以2*n(样本个数)
W(权值)和b(偏置值)的梯度和激活函数的梯度成正比，激活函数的梯度越大，wb调整的越快，训练收敛的也越快

交叉熵代价函数(cross-entropy)
w,b的调整与激活函数的导数无关，当误差越大的时候，参数的w,b调整的越快，收敛的越快

当输出神经元是线性的时候，选择二次代价函数，如果是S型函数，选择cross-entropy,这里的输出神经元即激活函数
sigmoid 双曲正切都是S型输出神经元

对数释然代价函数和softmax组合

tf.nn.sigmoid_cross_entropy_with_logits()
tf.nn.sofgmax_cross_entropy_with_logits()
"""

